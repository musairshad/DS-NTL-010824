{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Natural Language Processing: Classification\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "DS-NTL-010824<p>Phase 4</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# integrating our preprocessing into a pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import WordNetLemmatizer # lemmatizer using WordNet\n",
    "from nltk.corpus import wordnet # imports WordNet\n",
    "from nltk import pos_tag # nltk's native part of speech tagging\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import plot_confusion_matrix #depreciated\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,RocCurveDisplay,roc_auc_score\n",
    "#from sklearn.metrics import plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Build a very simple stateless transformer:\n",
    "- Cleans/preprocesses text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #define attributes to store if text preprocessing requires fitting from data\n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, y = 0):\n",
    "        # this is where you would fit things like corpus specific stopwords\n",
    "        # fit probable bigrams with bigram model in here\n",
    "        \n",
    "        # save as parameters of Text preprocessor\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, y = 0):\n",
    "        fully_normalized_corpus = data.apply(self.process_doc)\n",
    "        \n",
    "        return fully_normalized_corpus\n",
    "        \n",
    "    \n",
    "    def process_doc(self, doc):\n",
    "\n",
    "        #initialize lemmatizer\n",
    "        wnl = WordNetLemmatizer()\n",
    "        stop_words = stopwords.words('english')\n",
    "        \n",
    "        # helper function to change nltk's part of speech tagging to a wordnet format.\n",
    "        def pos_tagger(nltk_tag):\n",
    "            if nltk_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif nltk_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif nltk_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif nltk_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:         \n",
    "                return None\n",
    "\n",
    "\n",
    "        # remove stop words and punctuations, then lower case\n",
    "        doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]\n",
    "\n",
    "        #  POS detection on the result will be important in telling Wordnet's lemmatizer how to lemmatize\n",
    "\n",
    "        # creates list of tuples with tokens and POS tags in wordnet format\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "        doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "\n",
    "        return \" \".join(doc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/satire_nosatire.csv')\n",
    "X = data['body']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "proc = TextPreprocessor()\n",
    "\n",
    "transformed_train = proc.fit_transform(X_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prc_steps = [('countvec', CountVectorizer(min_df = 0.05, max_df = 0.95))]\n",
    "preprocess_pipeline = Pipeline(prc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_tr_proc = preprocess_pipeline.fit_transform(transformed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<700x602 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45177 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>additional</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  accord  account  accuse  act  action  activist  actually  add  \\\n",
       "0       0       0        0       1    0       0         0         0    0   \n",
       "1       0       1        0       0    0       0         0         0    1   \n",
       "2       0       0        0       0    0       0         0         0    0   \n",
       "3       0       0        0       0    0       0         0         0    0   \n",
       "4       0       0        0       1    0       0         2         0    0   \n",
       "..    ...     ...      ...     ...  ...     ...       ...       ...  ...   \n",
       "695     0       0        0       0    0       0         0         0    0   \n",
       "696     0       0        0       0    0       0         0         0    1   \n",
       "697     0       0        0       0    0       0         0         1    0   \n",
       "698     0       0        0       0    0       0         0         0    0   \n",
       "699     0       0        0       0    0       1         0         0    0   \n",
       "\n",
       "     additional  ...  word  work  worker  world  worry  write  year  yes  yet  \\\n",
       "0             0  ...     0     0       0      0      0      0     0    0    0   \n",
       "1             0  ...     0     1       0      0      0      0     1    0    0   \n",
       "2             0  ...     0     0       0      4      0      0     1    0    0   \n",
       "3             0  ...     0     2       0      0      0      1     0    0    0   \n",
       "4             0  ...     0     0       3      1      0      0     0    1    0   \n",
       "..          ...  ...   ...   ...     ...    ...    ...    ...   ...  ...  ...   \n",
       "695           0  ...     1     2       0      0      1      0     0    0    1   \n",
       "696           0  ...     0     0       0      0      0      0     1    1    0   \n",
       "697           0  ...     0     0       0      0      0      0     0    0    0   \n",
       "698           0  ...     0     0       0      0      0      0     3    0    0   \n",
       "699           0  ...     1     0       0      0      0      0     3    1    0   \n",
       "\n",
       "     young  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "695      0  \n",
       "696      0  \n",
       "697      0  \n",
       "698      0  \n",
       "699      0  \n",
       "\n",
       "[700 rows x 602 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = preprocess_pipeline[\n",
    "    'countvec'].get_feature_names()\n",
    "\n",
    "pd.DataFrame(X_tr_proc.toarray(), columns = feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Building a document classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Naive Bayes with Multinomial Distribution Likelihood**\n",
    "\n",
    "- Can be effective for modeling document-term frequency matrix to target class relationships\n",
    "-  \"naive\" assumption that the features (term frequencies) are conditionally independent given the class label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes theorem:\n",
    "\n",
    "$$ P(c|\\textbf{x}) = \\frac{P(\\textbf{x}|c)P(c)}{P(\\textbf{x})} $$\n",
    "\n",
    "- Likelihood; $P(\\textbf{x}|c)$\n",
    "- Prior: $P(c)$\n",
    "- Posterior: $P(c|\\textbf{x}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes classifier:\n",
    "    \n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Prior\n",
    "- simply the target fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_priors = y_train.value_counts()/y_train.shape[0]\n",
    "class_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**First step: word count distribution**:\n",
    "\n",
    "- Multinomial distribution (generalization of \n",
    "binomial distribution)\n",
    "\n",
    "For document with $m$ tokens:\n",
    "- dictionary of corpus has $d$ unique tokens.\n",
    "- $\\textbf{x} = (x_1,...., x_d)$ vector of token counts for document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An analogy: $d = 6$ M&M colors\n",
    "\n",
    "Picking $ m $ M&Ms.\n",
    "\n",
    "<img src = \"Images/picking_candy.jpg\" >\n",
    "    \n",
    "Follow multinomial distribution.\n",
    "\n",
    "\n",
    "<a href = \"https://www.mashed.com/679227/the-rarest-mm-color-may-surprise-you/#:~:text=Brown%20is%20currently%20the%20rarest%20color%20of%20M%26M's&text=As%20such%2C%20they%20used%20their,their%20findings%20were%20quite%20surprising.\"> Some interesting facts about M&Ms. </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ P(\\textbf{x}|\\theta) = \\frac{m!}{x_1!x_2!...x_d!} \\theta_{1}^{x_1}\\theta_{2}^{x_2}...\\theta_{d}^{x_d} $$\n",
    "Parameters of distribution:\n",
    "- $\\theta_i$: probability of picking $i^{th}$ token  in dictionary from bag of words\n",
    "\n",
    "**To be estimated from the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Words draws/order are **independent** of each other: the **naive** assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/scrabble.webp\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Second Step: class conditional word count\n",
    "\n",
    "$$ P(\\textbf{x}|c) = \\frac{m!}{x_1!x_2!...x_d!} [\\theta_c]_{1}^{x_1}[\\theta_c]_{2}^{x_2}...[\\theta_c]_{d}^{x_d} $$\n",
    "- $[\\theta_c]$ is **class-dependent** set of probability parameters.\n",
    "\n",
    "Need to fit probability parameters from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Fitting probability parameters for each class**\n",
    "\n",
    "- Very straightforward.\n",
    "- Probability of drawing token $i$ if document class $c$\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci}}{N_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Count token $i$ occurence across all documents of class $c$\n",
    "- Divide by total token count for all documents of class $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Getting the fit parameters with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>additional</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  accord  account  accuse  act  action  activist  actually  add  \\\n",
       "0       0       0        0       1    0       0         0         0    0   \n",
       "1       0       1        0       0    0       0         0         0    1   \n",
       "2       0       0        0       0    0       0         0         0    0   \n",
       "3       0       0        0       0    0       0         0         0    0   \n",
       "4       0       0        0       1    0       0         2         0    0   \n",
       "..    ...     ...      ...     ...  ...     ...       ...       ...  ...   \n",
       "695     0       0        0       0    0       0         0         0    0   \n",
       "696     0       0        0       0    0       0         0         0    1   \n",
       "697     0       0        0       0    0       0         0         1    0   \n",
       "698     0       0        0       0    0       0         0         0    0   \n",
       "699     0       0        0       0    0       1         0         0    0   \n",
       "\n",
       "     additional  ...  word  work  worker  world  worry  write  year  yes  yet  \\\n",
       "0             0  ...     0     0       0      0      0      0     0    0    0   \n",
       "1             0  ...     0     1       0      0      0      0     1    0    0   \n",
       "2             0  ...     0     0       0      4      0      0     1    0    0   \n",
       "3             0  ...     0     2       0      0      0      1     0    0    0   \n",
       "4             0  ...     0     0       3      1      0      0     0    1    0   \n",
       "..          ...  ...   ...   ...     ...    ...    ...    ...   ...  ...  ...   \n",
       "695           0  ...     1     2       0      0      1      0     0    0    1   \n",
       "696           0  ...     0     0       0      0      0      0     1    1    0   \n",
       "697           0  ...     0     0       0      0      0      0     0    0    0   \n",
       "698           0  ...     0     0       0      0      0      0     3    0    0   \n",
       "699           0  ...     1     0       0      0      0      0     3    1    0   \n",
       "\n",
       "     young  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "695      0  \n",
       "696      0  \n",
       "697      0  \n",
       "698      0  \n",
       "699      0  \n",
       "\n",
       "[700 rows x 602 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_mat = pd.DataFrame(X_tr_proc.toarray(), columns = feat_names)\n",
    "bow_mat['target'] = y_train\n",
    "bow_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "say       0.033241\n",
       "people    0.009515\n",
       "year      0.009304\n",
       "see       0.007588\n",
       "take      0.007527\n",
       "state     0.007437\n",
       "eu        0.007256\n",
       "go        0.006865\n",
       "get       0.006714\n",
       "make      0.006534\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_bow_mat = bow_mat[bow_mat['target'] == 1].drop(columns = ['target'])\n",
    "\n",
    "# class 1 token probabilities:\n",
    "N_tok_1 = class1_bow_mat.sum(axis = 0) # token occurence\n",
    "N_1 =  class1_bow_mat.values.sum() # number of tokens\n",
    "\n",
    "# get probabilities for each token: class 1\n",
    "proba_c1 = N_tok_1/N_1\n",
    "\n",
    "proba_c1.sort_values(ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "say           0.032553\n",
       "year          0.012070\n",
       "people        0.011485\n",
       "trump         0.010388\n",
       "state         0.008266\n",
       "government    0.007901\n",
       "president     0.007315\n",
       "get           0.006876\n",
       "time          0.006803\n",
       "take          0.006730\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_bow_mat = bow_mat[bow_mat['target'] == 0].drop(columns = ['target'])\n",
    "\n",
    "# class 0 token probabilities:\n",
    "N_tok_0 = class0_bow_mat.sum(axis = 0)\n",
    "N_0 =  class0_bow_mat.values.sum() \n",
    "\n",
    "# get probabilities for each token: class 0\n",
    "proba_c0 = N_tok_0/N_0\n",
    "\n",
    "proba_c0.sort_values(ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Computing likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speaking from his bunker deep in the Treasury, the Remoaner, Lord Haw Haw Hammond broadcasted that he is delighted with the punishment budget he will unleash across the whole of Britain. The Voice of the Axis “In line with my Remainer policies, and the vile impudent populace who voted for Brexit, I wish to punish you deeply by raising taxes and taking away funding from key areas of the economy. It’s because you people <spitting> still do not capitulate to our masters in Brussels. I was planted into this high position by our Remainer Prime Minister, Theresa May, and the Remainer led Cabinet. I am justified in punishing you British swine for your indiscretions. Haw, haw, haw, haw!” Many Brits who are already struggling under the regime of a Remainer-led Cabinet were naturally defiant about Lord Haw Haw Hammond’s punishment budget. “They can punish us as much as they want. They can have as many referendums as they want, we will not surrender, we will fight from the hill tops, we will fight from the beaches, we will fight from the city centres, we will fight from the Tesco car parks, we will never surrender to Brussels or to Lord Haw Haw Hammond and his vindictive spiteful taunts,” Reggie Churchill, 35, from Kent told local news services.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "able       0\n",
       "accord     0\n",
       "account    0\n",
       "accuse     0\n",
       "act        0\n",
       "          ..\n",
       "write      0\n",
       "year       0\n",
       "yes        0\n",
       "yet        0\n",
       "young      0\n",
       "Name: 50, Length: 601, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow vector for document\n",
    "bow_mat_feat = bow_mat.drop(columns = ['target'])\n",
    "word_vec = bow_mat_feat.iloc[50]\n",
    "word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_length = word_vec.sum()\n",
    "article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class1_likelihood = multinomial.pmf(x = word_vec.values, n = article_length, p =  proba_c1.values)\n",
    "class0_likelihood = multinomial.pmf(x = word_vec.values, n = article_length, p =  proba_c0.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now use Bayes theorem for classifier:\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "with multinomial likelihood\n",
    "\n",
    "$$ P(\\textbf{x}|c) = \\frac{m!}{x_1!x_2!...x_d!} [\\hat{\\theta}_c]_{1}^{x_1}[\\hat{\\theta}_c]_{2}^{x_2}...[\\hat{\\theta}_c]_{d}^{x_d} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and fitted parameters\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci}}{N_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate class for this document:\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6065138126391637e-74"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_likelihood*class_priors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.402394829433637e-79"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_likelihood*class_priors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given scale of probabilities:\n",
    "- Comparison done on log scale\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} \\Big[ \\log\\Big(P(\\textbf{x}|c)P(c)\\Big) \\Big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-73.7941155360775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(class1_likelihood*class_priors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78.19365754684966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(class0_likelihood*class_priors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Laplace Smoothing: practical correction\n",
    "\n",
    "- A fudge count $\\alpha$ added to token count in each class.\n",
    "- Avoids issues with having zero counts $N_c$ and $N_{ci}$ in training set.\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci} + \\alpha}{N_c + \\alpha d}$$\n",
    "\n",
    "- Typically $\\alpha = 1$. Can tune this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "- $d$ is the dimensionality of our vocabulary\n",
    "- $N_{ci}$ the count of token $i$ in class $c$\n",
    "- $N_{c}$ the count of all tokens in class $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Append Multinomial Naive Bayes Classifier to pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('multinb', MultinomialNB())]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "mod_pipe = deepcopy(preprocess_pipeline)\n",
    "mod_pipe.steps.append(('multinb', MultinomialNB()))\n",
    "mod_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       "                ('multinb', MultinomialNB())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pipe.fit(transformed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "transformed_test = proc.transform(X_test)\n",
    "\n",
    "y_pred = mod_pipe.predict(transformed_test) # automatically applies vectorizer and predicts on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       150\n",
      "           1       0.97      0.95      0.96       150\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633333333333334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_roc_curve(mod_pipe, transformed_test, y_test)\n",
    "#RocCurveDisplay.from_estimator\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(mod_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(mod_pipe, transformed_test, y_test);\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#ConfusionMatrixDisplay.from_estimator\n",
    "ConfusionMatrixDisplay(mod_pipe, transformed_test, y_test);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- with proper text preprocessing steps\n",
    "- Naive Bayes can perform really well on simple binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "TFIDF does not necessarily perform better than CV:\n",
    "- It is just a tool in our toolbelt often worth trying out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf', TfidfVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('multinb', MultinomialNB())]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "tfidfmod_pipe = deepcopy(mod_pipe)\n",
    "tfidfmod_pipe.steps[0] = ('tfidf', TfidfVectorizer(min_df=0.05, max_df=0.95)) # cuts words too rare/too frequent\n",
    "tfidfmod_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tfidfmod_pipe.fit(transformed_train, y_train)\n",
    "ypred_tfidf = tfidfmod_pipe.predict(transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566666666666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, ypred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConfusionMatrixDisplay' has no attribute 'from_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f5ecbb92ced6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot_confusion_matrix(tfidfmod_pipe, transformed_test, y_test);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidfmod_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ConfusionMatrixDisplay' has no attribute 'from_estimator'"
     ]
    }
   ],
   "source": [
    "#plot_confusion_matrix(tfidfmod_pipe, transformed_test, y_test);\n",
    "ConfusionMatrixDisplay.from_estimator(tfidfmod_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### With class imbalance\n",
    "\n",
    "- Modification to Multinomial Naive Bayes: Complement Naive Bayes\n",
    "- deals with data skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pretty much same fitting/hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('compnb', ComplementNB())]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "mod_comp_pipe = deepcopy(preprocess_pipeline)\n",
    "mod_comp_pipe.steps.append(('compnb', ComplementNB()))\n",
    "mod_comp_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       "                ('compnb', ComplementNB())])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_comp_pipe.fit(transformed_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test = proc.transform(X_test) #preprocess\n",
    "y_pred_comp = mod_comp_pipe.predict(transformed_test) #count vectorizer and ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       153\n",
      "           1       0.95      0.97      0.96       147\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_comp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ConfusionMatrixDisplay' has no attribute 'from_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2528e63ef0ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot_confusion_matrix(mod_comp_pipe, transformed_test, y_test);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_comp_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ConfusionMatrixDisplay' has no attribute 'from_estimator'"
     ]
    }
   ],
   "source": [
    "#plot_confusion_matrix(mod_comp_pipe, transformed_test, y_test);\n",
    "ConfusionMatrixDisplay.from_estimator(mod_comp_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Comparable performance on this balanced dataset. Will perform *much* better on imbalanced dataset than MultinomialNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
